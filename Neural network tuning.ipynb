{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necesary packages\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 1 - Tuning batch and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset for India diabetes\n",
    "data = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>757.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.844122</td>\n",
       "      <td>121.136063</td>\n",
       "      <td>69.690885</td>\n",
       "      <td>20.774108</td>\n",
       "      <td>80.841480</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.472437</td>\n",
       "      <td>33.281374</td>\n",
       "      <td>0.351387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369959</td>\n",
       "      <td>32.061428</td>\n",
       "      <td>18.283325</td>\n",
       "      <td>15.908567</td>\n",
       "      <td>115.710818</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.329474</td>\n",
       "      <td>11.697752</td>\n",
       "      <td>0.477719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   757.000000  757.000000     757.000000     757.000000  757.000000   \n",
       "mean      3.844122  121.136063      69.690885      20.774108   80.841480   \n",
       "std       3.369959   32.061428      18.283325      15.908567  115.710818   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      64.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   37.000000   \n",
       "75%       6.000000  141.000000      80.000000      32.000000  130.000000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  757.000000                757.000000  757.000000  757.000000  \n",
       "mean    32.457464                  0.472437   33.281374    0.351387  \n",
       "std      6.924988                  0.329474   11.697752    0.477719  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.244000   24.000000    0.000000  \n",
       "50%     32.300000                  0.376000   29.000000    0.000000  \n",
       "75%     36.600000                  0.627000   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data[data['BMI'] == 0]\n",
    "data.drop(mask.index, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.858711</td>\n",
       "      <td>121.046639</td>\n",
       "      <td>72.367627</td>\n",
       "      <td>21.499314</td>\n",
       "      <td>83.946502</td>\n",
       "      <td>32.469959</td>\n",
       "      <td>0.474117</td>\n",
       "      <td>33.318244</td>\n",
       "      <td>0.344307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.357468</td>\n",
       "      <td>32.255215</td>\n",
       "      <td>12.375838</td>\n",
       "      <td>15.708376</td>\n",
       "      <td>116.803000</td>\n",
       "      <td>6.885098</td>\n",
       "      <td>0.331649</td>\n",
       "      <td>11.753078</td>\n",
       "      <td>0.475468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   729.000000  729.000000     729.000000     729.000000  729.000000   \n",
       "mean      3.858711  121.046639      72.367627      21.499314   83.946502   \n",
       "std       3.357468   32.255215      12.375838      15.708376  116.803000   \n",
       "min       0.000000    0.000000      24.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      64.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      24.000000   46.000000   \n",
       "75%       6.000000  141.000000      80.000000      33.000000  130.000000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  729.000000                729.000000  729.000000  729.000000  \n",
       "mean    32.469959                  0.474117   33.318244    0.344307  \n",
       "std      6.885098                  0.331649   11.753078    0.475468  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.245000   24.000000    0.000000  \n",
       "50%     32.400000                  0.378000   29.000000    0.000000  \n",
       "75%     36.600000                  0.627000   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data[(data['BloodPressure'] == 0) & (data['Insulin'] == 0)]\n",
    "data.drop(mask.index, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into predictors and response\n",
    "X = data.iloc[:,0:8] #predictors\n",
    "Y = data.iloc[:,8] #response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2- Optimizing Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model\n",
    "def create_my_model(optimizer):\n",
    "    # create model\n",
    "    mymodel = Sequential()\n",
    "    mymodel.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    #mymodel.add(layers.Dropout(0.5))\n",
    "    mymodel.add(Dense(8, activation='relu'))\n",
    "    #mymodel.add(Dense(4, activation='relu'))\n",
    "    mymodel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    mymodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can you improve accuracy of the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_improved = KerasClassifier(build_fn=create_my_model, epochs=500, batch_size=10, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "73/73 [==============================] - 0s 487us/step - loss: 13.9756 - accuracy: 0.3292\n",
      "Epoch 2/500\n",
      "73/73 [==============================] - 0s 396us/step - loss: 2.2860 - accuracy: 0.4115\n",
      "Epoch 3/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 1.5459 - accuracy: 0.5089\n",
      "Epoch 4/500\n",
      "73/73 [==============================] - 0s 377us/step - loss: 1.1655 - accuracy: 0.5446\n",
      "Epoch 5/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.9409 - accuracy: 0.5967\n",
      "Epoch 6/500\n",
      "73/73 [==============================] - 0s 552us/step - loss: 0.8382 - accuracy: 0.6283\n",
      "Epoch 7/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.7612 - accuracy: 0.6667\n",
      "Epoch 8/500\n",
      "73/73 [==============================] - 0s 391us/step - loss: 0.7650 - accuracy: 0.6543\n",
      "Epoch 9/500\n",
      "73/73 [==============================] - 0s 387us/step - loss: 0.7199 - accuracy: 0.6927\n",
      "Epoch 10/500\n",
      "73/73 [==============================] - 0s 380us/step - loss: 0.6978 - accuracy: 0.7023\n",
      "Epoch 11/500\n",
      "73/73 [==============================] - 0s 380us/step - loss: 0.6618 - accuracy: 0.7023\n",
      "Epoch 12/500\n",
      "73/73 [==============================] - 0s 384us/step - loss: 0.6745 - accuracy: 0.7023\n",
      "Epoch 13/500\n",
      "73/73 [==============================] - 0s 378us/step - loss: 0.6444 - accuracy: 0.7215\n",
      "Epoch 14/500\n",
      "73/73 [==============================] - 0s 383us/step - loss: 0.6505 - accuracy: 0.7023\n",
      "Epoch 15/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.6396 - accuracy: 0.7078\n",
      "Epoch 16/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.6475 - accuracy: 0.7023\n",
      "Epoch 17/500\n",
      "73/73 [==============================] - 0s 376us/step - loss: 0.6365 - accuracy: 0.7106\n",
      "Epoch 18/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.6235 - accuracy: 0.6941\n",
      "Epoch 19/500\n",
      "73/73 [==============================] - 0s 354us/step - loss: 0.6400 - accuracy: 0.6941\n",
      "Epoch 20/500\n",
      "73/73 [==============================] - 0s 354us/step - loss: 0.6043 - accuracy: 0.7215\n",
      "Epoch 21/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.6105 - accuracy: 0.7092\n",
      "Epoch 22/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.6090 - accuracy: 0.7215\n",
      "Epoch 23/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.6290 - accuracy: 0.7023\n",
      "Epoch 24/500\n",
      "73/73 [==============================] - 0s 492us/step - loss: 0.6030 - accuracy: 0.7298\n",
      "Epoch 25/500\n",
      "73/73 [==============================] - 0s 534us/step - loss: 0.5904 - accuracy: 0.7215\n",
      "Epoch 26/500\n",
      "73/73 [==============================] - 0s 700us/step - loss: 0.5803 - accuracy: 0.7174\n",
      "Epoch 27/500\n",
      "73/73 [==============================] - 0s 654us/step - loss: 0.6142 - accuracy: 0.7064\n",
      "Epoch 28/500\n",
      "73/73 [==============================] - 0s 376us/step - loss: 0.5860 - accuracy: 0.7119\n",
      "Epoch 29/500\n",
      "73/73 [==============================] - 0s 387us/step - loss: 0.5839 - accuracy: 0.7133\n",
      "Epoch 30/500\n",
      "73/73 [==============================] - 0s 376us/step - loss: 0.5960 - accuracy: 0.7092\n",
      "Epoch 31/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.6145 - accuracy: 0.6968\n",
      "Epoch 32/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.6040 - accuracy: 0.7243\n",
      "Epoch 33/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.5807 - accuracy: 0.7284\n",
      "Epoch 34/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.6186 - accuracy: 0.7229\n",
      "Epoch 35/500\n",
      "73/73 [==============================] - 0s 565us/step - loss: 0.6101 - accuracy: 0.6996\n",
      "Epoch 36/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.5895 - accuracy: 0.7092\n",
      "Epoch 37/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.5748 - accuracy: 0.7229\n",
      "Epoch 38/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.5832 - accuracy: 0.7202\n",
      "Epoch 39/500\n",
      "73/73 [==============================] - 0s 379us/step - loss: 0.5809 - accuracy: 0.7188\n",
      "Epoch 40/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.5870 - accuracy: 0.7229\n",
      "Epoch 41/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.5941 - accuracy: 0.7270\n",
      "Epoch 42/500\n",
      "73/73 [==============================] - 0s 377us/step - loss: 0.5799 - accuracy: 0.7202\n",
      "Epoch 43/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.5744 - accuracy: 0.7243\n",
      "Epoch 44/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5675 - accuracy: 0.7311\n",
      "Epoch 45/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.5682 - accuracy: 0.7353\n",
      "Epoch 46/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.5794 - accuracy: 0.7215\n",
      "Epoch 47/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.6077 - accuracy: 0.7078\n",
      "Epoch 48/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.5513 - accuracy: 0.7490\n",
      "Epoch 49/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.5941 - accuracy: 0.7147\n",
      "Epoch 50/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.5614 - accuracy: 0.7202\n",
      "Epoch 51/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.5532 - accuracy: 0.7366\n",
      "Epoch 52/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.5729 - accuracy: 0.7147\n",
      "Epoch 53/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.5506 - accuracy: 0.7421\n",
      "Epoch 54/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.5546 - accuracy: 0.7339\n",
      "Epoch 55/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.5467 - accuracy: 0.7394\n",
      "Epoch 56/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.5665 - accuracy: 0.7284\n",
      "Epoch 57/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.5533 - accuracy: 0.7394\n",
      "Epoch 58/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.5448 - accuracy: 0.7339\n",
      "Epoch 59/500\n",
      "73/73 [==============================] - 0s 355us/step - loss: 0.5541 - accuracy: 0.7229\n",
      "Epoch 60/500\n",
      "73/73 [==============================] - 0s 392us/step - loss: 0.5530 - accuracy: 0.7270\n",
      "Epoch 61/500\n",
      "73/73 [==============================] - 0s 718us/step - loss: 0.5740 - accuracy: 0.7366\n",
      "Epoch 62/500\n",
      "73/73 [==============================] - 0s 420us/step - loss: 0.5688 - accuracy: 0.7188\n",
      "Epoch 63/500\n",
      "73/73 [==============================] - 0s 425us/step - loss: 0.5493 - accuracy: 0.7229\n",
      "Epoch 64/500\n",
      "73/73 [==============================] - 0s 406us/step - loss: 0.5419 - accuracy: 0.7339\n",
      "Epoch 65/500\n",
      "73/73 [==============================] - 0s 413us/step - loss: 0.5418 - accuracy: 0.7435\n",
      "Epoch 66/500\n",
      "73/73 [==============================] - 0s 394us/step - loss: 0.5452 - accuracy: 0.7476\n",
      "Epoch 67/500\n",
      "73/73 [==============================] - 0s 384us/step - loss: 0.5482 - accuracy: 0.7311\n",
      "Epoch 68/500\n",
      "73/73 [==============================] - 0s 396us/step - loss: 0.5615 - accuracy: 0.7092\n",
      "Epoch 69/500\n",
      "73/73 [==============================] - 0s 410us/step - loss: 0.5787 - accuracy: 0.6982\n",
      "Epoch 70/500\n",
      "73/73 [==============================] - 0s 466us/step - loss: 0.5747 - accuracy: 0.7174\n",
      "Epoch 71/500\n",
      "73/73 [==============================] - 0s 466us/step - loss: 0.5370 - accuracy: 0.7339\n",
      "Epoch 72/500\n",
      "73/73 [==============================] - 0s 420us/step - loss: 0.5703 - accuracy: 0.7257\n",
      "Epoch 73/500\n",
      "73/73 [==============================] - 0s 401us/step - loss: 0.5482 - accuracy: 0.7215\n",
      "Epoch 74/500\n",
      "73/73 [==============================] - 0s 377us/step - loss: 0.5310 - accuracy: 0.7435\n",
      "Epoch 75/500\n",
      "73/73 [==============================] - 0s 373us/step - loss: 0.5375 - accuracy: 0.7298\n",
      "Epoch 76/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.5528 - accuracy: 0.7353\n",
      "Epoch 77/500\n",
      "73/73 [==============================] - 0s 519us/step - loss: 0.5490 - accuracy: 0.7339\n",
      "Epoch 78/500\n",
      "73/73 [==============================] - 0s 425us/step - loss: 0.5378 - accuracy: 0.7380\n",
      "Epoch 79/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.5481 - accuracy: 0.7339\n",
      "Epoch 80/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.5517 - accuracy: 0.7284\n",
      "Epoch 81/500\n",
      "73/73 [==============================] - 0s 387us/step - loss: 0.5293 - accuracy: 0.7366\n",
      "Epoch 82/500\n",
      "73/73 [==============================] - 0s 373us/step - loss: 0.5249 - accuracy: 0.7476\n",
      "Epoch 83/500\n",
      "73/73 [==============================] - 0s 379us/step - loss: 0.5366 - accuracy: 0.7421\n",
      "Epoch 84/500\n",
      "73/73 [==============================] - 0s 395us/step - loss: 0.5270 - accuracy: 0.7366\n",
      "Epoch 85/500\n",
      "73/73 [==============================] - 0s 428us/step - loss: 0.5349 - accuracy: 0.7421\n",
      "Epoch 86/500\n",
      "73/73 [==============================] - 0s 407us/step - loss: 0.5341 - accuracy: 0.7380\n",
      "Epoch 87/500\n",
      "73/73 [==============================] - 0s 420us/step - loss: 0.5411 - accuracy: 0.7257\n",
      "Epoch 88/500\n",
      "73/73 [==============================] - 0s 422us/step - loss: 0.5368 - accuracy: 0.7325\n",
      "Epoch 89/500\n",
      "73/73 [==============================] - 0s 444us/step - loss: 0.5288 - accuracy: 0.7449\n",
      "Epoch 90/500\n",
      "73/73 [==============================] - 0s 445us/step - loss: 0.5248 - accuracy: 0.7435\n",
      "Epoch 91/500\n",
      "73/73 [==============================] - 0s 391us/step - loss: 0.5408 - accuracy: 0.7270\n",
      "Epoch 92/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.5306 - accuracy: 0.7325\n",
      "Epoch 93/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.5167 - accuracy: 0.7421\n",
      "Epoch 94/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.5338 - accuracy: 0.7449\n",
      "Epoch 95/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.5313 - accuracy: 0.7339\n",
      "Epoch 96/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.5442 - accuracy: 0.7476\n",
      "Epoch 97/500\n",
      "73/73 [==============================] - 0s 384us/step - loss: 0.5368 - accuracy: 0.7435\n",
      "Epoch 98/500\n",
      "73/73 [==============================] - 0s 381us/step - loss: 0.5165 - accuracy: 0.7586\n",
      "Epoch 99/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.5270 - accuracy: 0.7353\n",
      "Epoch 100/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.5174 - accuracy: 0.7490\n",
      "Epoch 101/500\n",
      "73/73 [==============================] - 0s 586us/step - loss: 0.5248 - accuracy: 0.7435\n",
      "Epoch 102/500\n",
      "73/73 [==============================] - 0s 390us/step - loss: 0.5156 - accuracy: 0.7517\n",
      "Epoch 103/500\n",
      "73/73 [==============================] - 0s 427us/step - loss: 0.5310 - accuracy: 0.7462\n",
      "Epoch 104/500\n",
      "73/73 [==============================] - 0s 441us/step - loss: 0.5233 - accuracy: 0.7353\n",
      "Epoch 105/500\n",
      "73/73 [==============================] - 0s 473us/step - loss: 0.5372 - accuracy: 0.7462\n",
      "Epoch 106/500\n",
      "73/73 [==============================] - 0s 438us/step - loss: 0.5251 - accuracy: 0.7298\n",
      "Epoch 107/500\n",
      "73/73 [==============================] - 0s 383us/step - loss: 0.5063 - accuracy: 0.7572\n",
      "Epoch 108/500\n",
      "73/73 [==============================] - 0s 382us/step - loss: 0.5072 - accuracy: 0.7545\n",
      "Epoch 109/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.5234 - accuracy: 0.7366\n",
      "Epoch 110/500\n",
      "73/73 [==============================] - 0s 379us/step - loss: 0.5514 - accuracy: 0.7160\n",
      "Epoch 111/500\n",
      "73/73 [==============================] - 0s 384us/step - loss: 0.5127 - accuracy: 0.7366\n",
      "Epoch 112/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.5116 - accuracy: 0.7531\n",
      "Epoch 113/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.5208 - accuracy: 0.7435\n",
      "Epoch 114/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.5123 - accuracy: 0.7586\n",
      "Epoch 115/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5057 - accuracy: 0.7545\n",
      "Epoch 116/500\n",
      "73/73 [==============================] - 0s 387us/step - loss: 0.5092 - accuracy: 0.7572\n",
      "Epoch 117/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5186 - accuracy: 0.7449\n",
      "Epoch 118/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5063 - accuracy: 0.7517\n",
      "Epoch 119/500\n",
      "73/73 [==============================] - 0s 386us/step - loss: 0.5217 - accuracy: 0.7394\n",
      "Epoch 120/500\n",
      "73/73 [==============================] - 0s 540us/step - loss: 0.5243 - accuracy: 0.7353\n",
      "Epoch 121/500\n",
      "73/73 [==============================] - 0s 435us/step - loss: 0.5065 - accuracy: 0.7654\n",
      "Epoch 122/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.5121 - accuracy: 0.7531\n",
      "Epoch 123/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.5067 - accuracy: 0.7476\n",
      "Epoch 124/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.5183 - accuracy: 0.7641\n",
      "Epoch 125/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.5145 - accuracy: 0.7353\n",
      "Epoch 126/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.5164 - accuracy: 0.7613\n",
      "Epoch 127/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.5082 - accuracy: 0.7517\n",
      "Epoch 128/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.5140 - accuracy: 0.7476\n",
      "Epoch 129/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.5034 - accuracy: 0.7723\n",
      "Epoch 130/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.5092 - accuracy: 0.7517\n",
      "Epoch 131/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.5051 - accuracy: 0.7613\n",
      "Epoch 132/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5064 - accuracy: 0.7545\n",
      "Epoch 133/500\n",
      "73/73 [==============================] - 0s 416us/step - loss: 0.5033 - accuracy: 0.7503\n",
      "Epoch 134/500\n",
      "73/73 [==============================] - 0s 373us/step - loss: 0.5039 - accuracy: 0.7558\n",
      "Epoch 135/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4920 - accuracy: 0.7572\n",
      "Epoch 136/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5138 - accuracy: 0.7449\n",
      "Epoch 137/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4975 - accuracy: 0.7709\n",
      "Epoch 138/500\n",
      "73/73 [==============================] - 0s 376us/step - loss: 0.4942 - accuracy: 0.7531\n",
      "Epoch 139/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.5047 - accuracy: 0.7586\n",
      "Epoch 140/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4984 - accuracy: 0.7641\n",
      "Epoch 141/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.5032 - accuracy: 0.7503\n",
      "Epoch 142/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5009 - accuracy: 0.7490\n",
      "Epoch 143/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.5102 - accuracy: 0.7613\n",
      "Epoch 144/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4933 - accuracy: 0.7613\n",
      "Epoch 145/500\n",
      "73/73 [==============================] - 0s 559us/step - loss: 0.5004 - accuracy: 0.7737\n",
      "Epoch 146/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.5093 - accuracy: 0.7503\n",
      "Epoch 147/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4978 - accuracy: 0.7641\n",
      "Epoch 148/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.5107 - accuracy: 0.7545\n",
      "Epoch 149/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.5120 - accuracy: 0.7558\n",
      "Epoch 150/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4861 - accuracy: 0.7682\n",
      "Epoch 151/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.4912 - accuracy: 0.7503\n",
      "Epoch 152/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5068 - accuracy: 0.7599\n",
      "Epoch 153/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.5067 - accuracy: 0.7599\n",
      "Epoch 154/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.5022 - accuracy: 0.7586\n",
      "Epoch 155/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.5047 - accuracy: 0.7517\n",
      "Epoch 156/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.5152 - accuracy: 0.7627\n",
      "Epoch 157/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4969 - accuracy: 0.7572\n",
      "Epoch 158/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.4948 - accuracy: 0.7613\n",
      "Epoch 159/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4923 - accuracy: 0.7572\n",
      "Epoch 160/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4939 - accuracy: 0.7709\n",
      "Epoch 161/500\n",
      "73/73 [==============================] - 0s 391us/step - loss: 0.5005 - accuracy: 0.7599\n",
      "Epoch 162/500\n",
      "73/73 [==============================] - 0s 381us/step - loss: 0.4963 - accuracy: 0.7641\n",
      "Epoch 163/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4935 - accuracy: 0.7668\n",
      "Epoch 164/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.5017 - accuracy: 0.7599\n",
      "Epoch 165/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4946 - accuracy: 0.7737\n",
      "Epoch 166/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4957 - accuracy: 0.7641\n",
      "Epoch 167/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4799 - accuracy: 0.7641\n",
      "Epoch 168/500\n",
      "73/73 [==============================] - 0s 590us/step - loss: 0.4974 - accuracy: 0.7476\n",
      "Epoch 169/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.4880 - accuracy: 0.7695\n",
      "Epoch 170/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4947 - accuracy: 0.7641\n",
      "Epoch 171/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.4852 - accuracy: 0.7682\n",
      "Epoch 172/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.4948 - accuracy: 0.7572\n",
      "Epoch 173/500\n",
      "73/73 [==============================] - 0s 377us/step - loss: 0.5007 - accuracy: 0.7545\n",
      "Epoch 174/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4817 - accuracy: 0.7695\n",
      "Epoch 175/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4847 - accuracy: 0.7750\n",
      "Epoch 176/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4903 - accuracy: 0.7572\n",
      "Epoch 177/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4917 - accuracy: 0.7627\n",
      "Epoch 178/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4847 - accuracy: 0.7682\n",
      "Epoch 179/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4833 - accuracy: 0.7750\n",
      "Epoch 180/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.4823 - accuracy: 0.7750\n",
      "Epoch 181/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4858 - accuracy: 0.7558\n",
      "Epoch 182/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4934 - accuracy: 0.7737\n",
      "Epoch 183/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4773 - accuracy: 0.7846\n",
      "Epoch 184/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4863 - accuracy: 0.7531\n",
      "Epoch 185/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4821 - accuracy: 0.7682\n",
      "Epoch 186/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.4753 - accuracy: 0.7833\n",
      "Epoch 187/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.4894 - accuracy: 0.7791\n",
      "Epoch 188/500\n",
      "73/73 [==============================] - 0s 580us/step - loss: 0.4787 - accuracy: 0.7791\n",
      "Epoch 189/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4810 - accuracy: 0.7695\n",
      "Epoch 190/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4846 - accuracy: 0.7627\n",
      "Epoch 191/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4779 - accuracy: 0.7723\n",
      "Epoch 192/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4779 - accuracy: 0.7737\n",
      "Epoch 193/500\n",
      "73/73 [==============================] - 0s 381us/step - loss: 0.4888 - accuracy: 0.7517\n",
      "Epoch 194/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4869 - accuracy: 0.7668\n",
      "Epoch 195/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4986 - accuracy: 0.7627\n",
      "Epoch 196/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4775 - accuracy: 0.7833\n",
      "Epoch 197/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4829 - accuracy: 0.7764\n",
      "Epoch 198/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4790 - accuracy: 0.7764\n",
      "Epoch 199/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.4894 - accuracy: 0.7586\n",
      "Epoch 200/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4702 - accuracy: 0.7737\n",
      "Epoch 201/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4902 - accuracy: 0.7654\n",
      "Epoch 202/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4767 - accuracy: 0.7737\n",
      "Epoch 203/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4728 - accuracy: 0.7764\n",
      "Epoch 204/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4756 - accuracy: 0.7641\n",
      "Epoch 205/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4825 - accuracy: 0.7668\n",
      "Epoch 206/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4900 - accuracy: 0.7709\n",
      "Epoch 207/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4827 - accuracy: 0.7599\n",
      "Epoch 208/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4786 - accuracy: 0.7695\n",
      "Epoch 209/500\n",
      "73/73 [==============================] - 0s 587us/step - loss: 0.4754 - accuracy: 0.7695\n",
      "Epoch 210/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4857 - accuracy: 0.7613\n",
      "Epoch 211/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4662 - accuracy: 0.7764\n",
      "Epoch 212/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4735 - accuracy: 0.7695\n",
      "Epoch 213/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4793 - accuracy: 0.7682\n",
      "Epoch 214/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4782 - accuracy: 0.7641\n",
      "Epoch 215/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4673 - accuracy: 0.7860\n",
      "Epoch 216/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4678 - accuracy: 0.7791\n",
      "Epoch 217/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4699 - accuracy: 0.7833\n",
      "Epoch 218/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4794 - accuracy: 0.7709\n",
      "Epoch 219/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4826 - accuracy: 0.7599\n",
      "Epoch 220/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4754 - accuracy: 0.7668\n",
      "Epoch 221/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4816 - accuracy: 0.7723\n",
      "Epoch 222/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4827 - accuracy: 0.7764\n",
      "Epoch 223/500\n",
      "73/73 [==============================] - 0s 375us/step - loss: 0.4744 - accuracy: 0.7737\n",
      "Epoch 224/500\n",
      "73/73 [==============================] - 0s 403us/step - loss: 0.4736 - accuracy: 0.7750\n",
      "Epoch 225/500\n",
      "73/73 [==============================] - 0s 390us/step - loss: 0.4777 - accuracy: 0.7778\n",
      "Epoch 226/500\n",
      "73/73 [==============================] - 0s 386us/step - loss: 0.4744 - accuracy: 0.7860\n",
      "Epoch 227/500\n",
      "73/73 [==============================] - 0s 810us/step - loss: 0.4889 - accuracy: 0.7558\n",
      "Epoch 228/500\n",
      "73/73 [==============================] - 0s 446us/step - loss: 0.4747 - accuracy: 0.7750\n",
      "Epoch 229/500\n",
      "73/73 [==============================] - 0s 427us/step - loss: 0.4687 - accuracy: 0.7805\n",
      "Epoch 230/500\n",
      "73/73 [==============================] - 0s 440us/step - loss: 0.4657 - accuracy: 0.7778\n",
      "Epoch 231/500\n",
      "73/73 [==============================] - 0s 427us/step - loss: 0.4733 - accuracy: 0.7805\n",
      "Epoch 232/500\n",
      "73/73 [==============================] - 0s 429us/step - loss: 0.4727 - accuracy: 0.7723\n",
      "Epoch 233/500\n",
      "73/73 [==============================] - 0s 429us/step - loss: 0.4646 - accuracy: 0.7833\n",
      "Epoch 234/500\n",
      "73/73 [==============================] - 0s 423us/step - loss: 0.4676 - accuracy: 0.7723\n",
      "Epoch 235/500\n",
      "73/73 [==============================] - 0s 443us/step - loss: 0.4601 - accuracy: 0.7778\n",
      "Epoch 236/500\n",
      "73/73 [==============================] - 0s 501us/step - loss: 0.4698 - accuracy: 0.7764\n",
      "Epoch 237/500\n",
      "73/73 [==============================] - 0s 454us/step - loss: 0.4790 - accuracy: 0.7654\n",
      "Epoch 238/500\n",
      "73/73 [==============================] - 0s 452us/step - loss: 0.4674 - accuracy: 0.7764\n",
      "Epoch 239/500\n",
      "73/73 [==============================] - 0s 414us/step - loss: 0.4693 - accuracy: 0.7750\n",
      "Epoch 240/500\n",
      "73/73 [==============================] - 0s 380us/step - loss: 0.4596 - accuracy: 0.7819\n",
      "Epoch 241/500\n",
      "73/73 [==============================] - 0s 379us/step - loss: 0.4605 - accuracy: 0.7833\n",
      "Epoch 242/500\n",
      "73/73 [==============================] - 0s 578us/step - loss: 0.4631 - accuracy: 0.7805\n",
      "Epoch 243/500\n",
      "73/73 [==============================] - 0s 383us/step - loss: 0.4705 - accuracy: 0.7723\n",
      "Epoch 244/500\n",
      "73/73 [==============================] - 0s 378us/step - loss: 0.4710 - accuracy: 0.7654\n",
      "Epoch 245/500\n",
      "73/73 [==============================] - 0s 373us/step - loss: 0.5129 - accuracy: 0.7462\n",
      "Epoch 246/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4604 - accuracy: 0.7778\n",
      "Epoch 247/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4777 - accuracy: 0.7668\n",
      "Epoch 248/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4819 - accuracy: 0.7819\n",
      "Epoch 249/500\n",
      "73/73 [==============================] - 0s 373us/step - loss: 0.4646 - accuracy: 0.7929\n",
      "Epoch 250/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4615 - accuracy: 0.7723\n",
      "Epoch 251/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4631 - accuracy: 0.7819\n",
      "Epoch 252/500\n",
      "73/73 [==============================] - 0s 377us/step - loss: 0.4737 - accuracy: 0.7778\n",
      "Epoch 253/500\n",
      "73/73 [==============================] - 0s 382us/step - loss: 0.4680 - accuracy: 0.7668\n",
      "Epoch 254/500\n",
      "73/73 [==============================] - 0s 374us/step - loss: 0.4668 - accuracy: 0.7682\n",
      "Epoch 255/500\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7668\n",
      "Epoch 256/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4618 - accuracy: 0.7764\n",
      "Epoch 257/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4696 - accuracy: 0.7641\n",
      "Epoch 258/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4634 - accuracy: 0.7846\n",
      "Epoch 259/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4665 - accuracy: 0.7833\n",
      "Epoch 260/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4737 - accuracy: 0.7737\n",
      "Epoch 261/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4649 - accuracy: 0.7764\n",
      "Epoch 262/500\n",
      "73/73 [==============================] - 0s 475us/step - loss: 0.4753 - accuracy: 0.7764\n",
      "Epoch 263/500\n",
      "73/73 [==============================] - 0s 423us/step - loss: 0.4528 - accuracy: 0.7860\n",
      "Epoch 264/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.4847 - accuracy: 0.7709\n",
      "Epoch 265/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4616 - accuracy: 0.7709\n",
      "Epoch 266/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4660 - accuracy: 0.7833\n",
      "Epoch 267/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4659 - accuracy: 0.7695\n",
      "Epoch 268/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4560 - accuracy: 0.7723\n",
      "Epoch 269/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4608 - accuracy: 0.7778\n",
      "Epoch 270/500\n",
      "73/73 [==============================] - 0s 376us/step - loss: 0.4579 - accuracy: 0.7846\n",
      "Epoch 271/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4575 - accuracy: 0.8011\n",
      "Epoch 272/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.4588 - accuracy: 0.7805\n",
      "Epoch 273/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.4631 - accuracy: 0.7723\n",
      "Epoch 274/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4571 - accuracy: 0.7791\n",
      "Epoch 275/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4724 - accuracy: 0.7613\n",
      "Epoch 276/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4597 - accuracy: 0.7750\n",
      "Epoch 277/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4753 - accuracy: 0.7668\n",
      "Epoch 278/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4657 - accuracy: 0.7833\n",
      "Epoch 279/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4591 - accuracy: 0.7846\n",
      "Epoch 280/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4679 - accuracy: 0.7833\n",
      "Epoch 281/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4621 - accuracy: 0.7846\n",
      "Epoch 282/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4675 - accuracy: 0.7709\n",
      "Epoch 283/500\n",
      "73/73 [==============================] - 0s 564us/step - loss: 0.4498 - accuracy: 0.7915\n",
      "Epoch 284/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4573 - accuracy: 0.7846\n",
      "Epoch 285/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4554 - accuracy: 0.7888\n",
      "Epoch 286/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4475 - accuracy: 0.7984\n",
      "Epoch 287/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4559 - accuracy: 0.7778\n",
      "Epoch 288/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4595 - accuracy: 0.7791\n",
      "Epoch 289/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4735 - accuracy: 0.7682\n",
      "Epoch 290/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4582 - accuracy: 0.7805\n",
      "Epoch 291/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4536 - accuracy: 0.7888\n",
      "Epoch 292/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4665 - accuracy: 0.7682\n",
      "Epoch 293/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4421 - accuracy: 0.7915\n",
      "Epoch 294/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4543 - accuracy: 0.7915\n",
      "Epoch 295/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4545 - accuracy: 0.7723\n",
      "Epoch 296/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4497 - accuracy: 0.7942\n",
      "Epoch 297/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4603 - accuracy: 0.7819\n",
      "Epoch 298/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4598 - accuracy: 0.7833\n",
      "Epoch 299/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4722 - accuracy: 0.7695\n",
      "Epoch 300/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4526 - accuracy: 0.7860\n",
      "Epoch 301/500\n",
      "73/73 [==============================] - 0s 585us/step - loss: 0.4675 - accuracy: 0.7695\n",
      "Epoch 302/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4591 - accuracy: 0.7833\n",
      "Epoch 303/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4577 - accuracy: 0.7791\n",
      "Epoch 304/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4504 - accuracy: 0.7942\n",
      "Epoch 305/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4554 - accuracy: 0.7833\n",
      "Epoch 306/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.4552 - accuracy: 0.7874\n",
      "Epoch 307/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4723 - accuracy: 0.7641\n",
      "Epoch 308/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4559 - accuracy: 0.7819\n",
      "Epoch 309/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4416 - accuracy: 0.7956\n",
      "Epoch 310/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4498 - accuracy: 0.7874\n",
      "Epoch 311/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4494 - accuracy: 0.7805\n",
      "Epoch 312/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4736 - accuracy: 0.7723\n",
      "Epoch 313/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4642 - accuracy: 0.7819\n",
      "Epoch 314/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4510 - accuracy: 0.7874\n",
      "Epoch 315/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4543 - accuracy: 0.7833\n",
      "Epoch 316/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4527 - accuracy: 0.7888\n",
      "Epoch 317/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4505 - accuracy: 0.7819\n",
      "Epoch 318/500\n",
      "73/73 [==============================] - 0s 569us/step - loss: 0.4482 - accuracy: 0.7764\n",
      "Epoch 319/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4603 - accuracy: 0.7737\n",
      "Epoch 320/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4638 - accuracy: 0.7764\n",
      "Epoch 321/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4551 - accuracy: 0.7846\n",
      "Epoch 322/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4541 - accuracy: 0.7846\n",
      "Epoch 323/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4646 - accuracy: 0.7860\n",
      "Epoch 324/500\n",
      "73/73 [==============================] - 0s 353us/step - loss: 0.4654 - accuracy: 0.7778\n",
      "Epoch 325/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4580 - accuracy: 0.7956\n",
      "Epoch 326/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4513 - accuracy: 0.7942\n",
      "Epoch 327/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4469 - accuracy: 0.7915\n",
      "Epoch 328/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4483 - accuracy: 0.7929\n",
      "Epoch 329/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4490 - accuracy: 0.7888\n",
      "Epoch 330/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4429 - accuracy: 0.7888\n",
      "Epoch 331/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4621 - accuracy: 0.7846\n",
      "Epoch 332/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4412 - accuracy: 0.7929\n",
      "Epoch 333/500\n",
      "73/73 [==============================] - 0s 355us/step - loss: 0.4475 - accuracy: 0.7956\n",
      "Epoch 334/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4450 - accuracy: 0.7984\n",
      "Epoch 335/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4376 - accuracy: 0.7956\n",
      "Epoch 336/500\n",
      "73/73 [==============================] - 0s 604us/step - loss: 0.4423 - accuracy: 0.7901\n",
      "Epoch 337/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4497 - accuracy: 0.7819\n",
      "Epoch 338/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4493 - accuracy: 0.7764\n",
      "Epoch 339/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4517 - accuracy: 0.7888\n",
      "Epoch 340/500\n",
      "73/73 [==============================] - 0s 369us/step - loss: 0.4545 - accuracy: 0.7819\n",
      "Epoch 341/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4569 - accuracy: 0.7846\n",
      "Epoch 342/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4519 - accuracy: 0.7846\n",
      "Epoch 343/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4419 - accuracy: 0.7833\n",
      "Epoch 344/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4412 - accuracy: 0.7997\n",
      "Epoch 345/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4374 - accuracy: 0.8052\n",
      "Epoch 346/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4461 - accuracy: 0.7901\n",
      "Epoch 347/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4487 - accuracy: 0.7874\n",
      "Epoch 348/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.4545 - accuracy: 0.7915\n",
      "Epoch 349/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4403 - accuracy: 0.7997\n",
      "Epoch 350/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4488 - accuracy: 0.7819\n",
      "Epoch 351/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4951 - accuracy: 0.7599\n",
      "Epoch 352/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4468 - accuracy: 0.7901\n",
      "Epoch 353/500\n",
      "73/73 [==============================] - 0s 581us/step - loss: 0.4453 - accuracy: 0.7846\n",
      "Epoch 354/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4431 - accuracy: 0.7942\n",
      "Epoch 355/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4371 - accuracy: 0.7997\n",
      "Epoch 356/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4390 - accuracy: 0.8025\n",
      "Epoch 357/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4359 - accuracy: 0.7929\n",
      "Epoch 358/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4370 - accuracy: 0.7915\n",
      "Epoch 359/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4494 - accuracy: 0.7888\n",
      "Epoch 360/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4441 - accuracy: 0.7860\n",
      "Epoch 361/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4377 - accuracy: 0.7997\n",
      "Epoch 362/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.4457 - accuracy: 0.7846\n",
      "Epoch 363/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4440 - accuracy: 0.7942\n",
      "Epoch 364/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4354 - accuracy: 0.8011\n",
      "Epoch 365/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4449 - accuracy: 0.7929\n",
      "Epoch 366/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4452 - accuracy: 0.7970\n",
      "Epoch 367/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4761 - accuracy: 0.7654\n",
      "Epoch 368/500\n",
      "73/73 [==============================] - 0s 562us/step - loss: 0.4474 - accuracy: 0.8011\n",
      "Epoch 369/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4591 - accuracy: 0.7737\n",
      "Epoch 370/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4502 - accuracy: 0.7819\n",
      "Epoch 371/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4507 - accuracy: 0.7778\n",
      "Epoch 372/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4428 - accuracy: 0.7956\n",
      "Epoch 373/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4543 - accuracy: 0.7942\n",
      "Epoch 374/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4371 - accuracy: 0.7997\n",
      "Epoch 375/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4406 - accuracy: 0.7942\n",
      "Epoch 376/500\n",
      "73/73 [==============================] - 0s 353us/step - loss: 0.4439 - accuracy: 0.7888\n",
      "Epoch 377/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4462 - accuracy: 0.7874\n",
      "Epoch 378/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4370 - accuracy: 0.7942\n",
      "Epoch 379/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4555 - accuracy: 0.7915\n",
      "Epoch 380/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4452 - accuracy: 0.7929\n",
      "Epoch 381/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4349 - accuracy: 0.7929\n",
      "Epoch 382/500\n",
      "73/73 [==============================] - 0s 371us/step - loss: 0.4421 - accuracy: 0.7764\n",
      "Epoch 383/500\n",
      "73/73 [==============================] - 0s 370us/step - loss: 0.4355 - accuracy: 0.7997\n",
      "Epoch 384/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4659 - accuracy: 0.7915\n",
      "Epoch 385/500\n",
      "73/73 [==============================] - 0s 566us/step - loss: 0.4326 - accuracy: 0.8025\n",
      "Epoch 386/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4553 - accuracy: 0.7846\n",
      "Epoch 387/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4424 - accuracy: 0.7819\n",
      "Epoch 388/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4381 - accuracy: 0.7929\n",
      "Epoch 389/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4543 - accuracy: 0.7805\n",
      "Epoch 390/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4581 - accuracy: 0.7860\n",
      "Epoch 391/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4358 - accuracy: 0.7874\n",
      "Epoch 392/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4357 - accuracy: 0.7997\n",
      "Epoch 393/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4402 - accuracy: 0.7901\n",
      "Epoch 394/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4297 - accuracy: 0.8025\n",
      "Epoch 395/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4399 - accuracy: 0.7846\n",
      "Epoch 396/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4638 - accuracy: 0.7874\n",
      "Epoch 397/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4437 - accuracy: 0.7874\n",
      "Epoch 398/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4434 - accuracy: 0.7956\n",
      "Epoch 399/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4364 - accuracy: 0.7984\n",
      "Epoch 400/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4372 - accuracy: 0.7956\n",
      "Epoch 401/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.4413 - accuracy: 0.7929\n",
      "Epoch 402/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4489 - accuracy: 0.8011\n",
      "Epoch 403/500\n",
      "73/73 [==============================] - 0s 372us/step - loss: 0.4480 - accuracy: 0.7956\n",
      "Epoch 404/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4440 - accuracy: 0.7846\n",
      "Epoch 405/500\n",
      "73/73 [==============================] - 0s 550us/step - loss: 0.4332 - accuracy: 0.7956\n",
      "Epoch 406/500\n",
      "73/73 [==============================] - 0s 373us/step - loss: 0.4556 - accuracy: 0.7791\n",
      "Epoch 407/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4634 - accuracy: 0.7805\n",
      "Epoch 408/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4427 - accuracy: 0.7888\n",
      "Epoch 409/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4360 - accuracy: 0.7929\n",
      "Epoch 410/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4550 - accuracy: 0.7874\n",
      "Epoch 411/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4480 - accuracy: 0.7846\n",
      "Epoch 412/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4377 - accuracy: 0.7984\n",
      "Epoch 413/500\n",
      "73/73 [==============================] - 0s 355us/step - loss: 0.4462 - accuracy: 0.8038\n",
      "Epoch 414/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4531 - accuracy: 0.8038\n",
      "Epoch 415/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4309 - accuracy: 0.7984\n",
      "Epoch 416/500\n",
      "73/73 [==============================] - 0s 357us/step - loss: 0.4316 - accuracy: 0.7997\n",
      "Epoch 417/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4390 - accuracy: 0.7942\n",
      "Epoch 418/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4340 - accuracy: 0.7956\n",
      "Epoch 419/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.4459 - accuracy: 0.7860\n",
      "Epoch 420/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4319 - accuracy: 0.7901\n",
      "Epoch 421/500\n",
      "73/73 [==============================] - 0s 595us/step - loss: 0.4425 - accuracy: 0.7819\n",
      "Epoch 422/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4324 - accuracy: 0.7984\n",
      "Epoch 423/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4337 - accuracy: 0.7819\n",
      "Epoch 424/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4431 - accuracy: 0.7942\n",
      "Epoch 425/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4323 - accuracy: 0.8038\n",
      "Epoch 426/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4433 - accuracy: 0.7915\n",
      "Epoch 427/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4408 - accuracy: 0.7970\n",
      "Epoch 428/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4565 - accuracy: 0.7819\n",
      "Epoch 429/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4367 - accuracy: 0.7929\n",
      "Epoch 430/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4512 - accuracy: 0.7929\n",
      "Epoch 431/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.4288 - accuracy: 0.7929\n",
      "Epoch 432/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4433 - accuracy: 0.7970\n",
      "Epoch 433/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4455 - accuracy: 0.7805\n",
      "Epoch 434/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4357 - accuracy: 0.7915\n",
      "Epoch 435/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4372 - accuracy: 0.7956\n",
      "Epoch 436/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4345 - accuracy: 0.7915\n",
      "Epoch 437/500\n",
      "73/73 [==============================] - 0s 589us/step - loss: 0.4411 - accuracy: 0.7901\n",
      "Epoch 438/500\n",
      "73/73 [==============================] - 0s 424us/step - loss: 0.4492 - accuracy: 0.7874\n",
      "Epoch 439/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4397 - accuracy: 0.7970\n",
      "Epoch 440/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4389 - accuracy: 0.7819\n",
      "Epoch 441/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4878 - accuracy: 0.7805\n",
      "Epoch 442/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4331 - accuracy: 0.8011\n",
      "Epoch 443/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4315 - accuracy: 0.7915\n",
      "Epoch 444/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4305 - accuracy: 0.7984\n",
      "Epoch 445/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4298 - accuracy: 0.8011\n",
      "Epoch 446/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4560 - accuracy: 0.7888\n",
      "Epoch 447/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4451 - accuracy: 0.8025\n",
      "Epoch 448/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4397 - accuracy: 0.8052\n",
      "Epoch 449/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4302 - accuracy: 0.7929\n",
      "Epoch 450/500\n",
      "73/73 [==============================] - 0s 354us/step - loss: 0.4449 - accuracy: 0.7846\n",
      "Epoch 451/500\n",
      "73/73 [==============================] - 0s 352us/step - loss: 0.4336 - accuracy: 0.7901\n",
      "Epoch 452/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.4333 - accuracy: 0.7942\n",
      "Epoch 453/500\n",
      "73/73 [==============================] - 0s 567us/step - loss: 0.4484 - accuracy: 0.7723\n",
      "Epoch 454/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4333 - accuracy: 0.7997\n",
      "Epoch 455/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4406 - accuracy: 0.8011\n",
      "Epoch 456/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4235 - accuracy: 0.8107\n",
      "Epoch 457/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4369 - accuracy: 0.8011\n",
      "Epoch 458/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4374 - accuracy: 0.8038\n",
      "Epoch 459/500\n",
      "73/73 [==============================] - 0s 367us/step - loss: 0.4320 - accuracy: 0.8052\n",
      "Epoch 460/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4331 - accuracy: 0.7956\n",
      "Epoch 461/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4258 - accuracy: 0.7901\n",
      "Epoch 462/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4400 - accuracy: 0.7915\n",
      "Epoch 463/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4386 - accuracy: 0.7956\n",
      "Epoch 464/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4296 - accuracy: 0.7888\n",
      "Epoch 465/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4298 - accuracy: 0.8134\n",
      "Epoch 466/500\n",
      "73/73 [==============================] - 0s 355us/step - loss: 0.4298 - accuracy: 0.8066\n",
      "Epoch 467/500\n",
      "73/73 [==============================] - 0s 560us/step - loss: 0.4375 - accuracy: 0.7956\n",
      "Epoch 468/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4361 - accuracy: 0.7984\n",
      "Epoch 469/500\n",
      "73/73 [==============================] - 0s 365us/step - loss: 0.4393 - accuracy: 0.7942\n",
      "Epoch 470/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4308 - accuracy: 0.8066\n",
      "Epoch 471/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4302 - accuracy: 0.7970\n",
      "Epoch 472/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4249 - accuracy: 0.8080\n",
      "Epoch 473/500\n",
      "73/73 [==============================] - 0s 368us/step - loss: 0.4313 - accuracy: 0.7956\n",
      "Epoch 474/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4300 - accuracy: 0.7970\n",
      "Epoch 475/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4341 - accuracy: 0.8052\n",
      "Epoch 476/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4412 - accuracy: 0.7874\n",
      "Epoch 477/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4584 - accuracy: 0.7833\n",
      "Epoch 478/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4316 - accuracy: 0.7970\n",
      "Epoch 479/500\n",
      "73/73 [==============================] - 0s 362us/step - loss: 0.4509 - accuracy: 0.7888\n",
      "Epoch 480/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4367 - accuracy: 0.7984\n",
      "Epoch 481/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4282 - accuracy: 0.8011\n",
      "Epoch 482/500\n",
      "73/73 [==============================] - 0s 355us/step - loss: 0.4469 - accuracy: 0.8025\n",
      "Epoch 483/500\n",
      "73/73 [==============================] - 0s 361us/step - loss: 0.4375 - accuracy: 0.8011\n",
      "Epoch 484/500\n",
      "73/73 [==============================] - 0s 579us/step - loss: 0.4499 - accuracy: 0.7846\n",
      "Epoch 485/500\n",
      "73/73 [==============================] - 0s 359us/step - loss: 0.4343 - accuracy: 0.7874\n",
      "Epoch 486/500\n",
      "73/73 [==============================] - 0s 353us/step - loss: 0.4288 - accuracy: 0.7929\n",
      "Epoch 487/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4346 - accuracy: 0.7915\n",
      "Epoch 488/500\n",
      "73/73 [==============================] - 0s 354us/step - loss: 0.4435 - accuracy: 0.7888\n",
      "Epoch 489/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4389 - accuracy: 0.8038\n",
      "Epoch 490/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4325 - accuracy: 0.7942\n",
      "Epoch 491/500\n",
      "73/73 [==============================] - 0s 363us/step - loss: 0.4314 - accuracy: 0.7929\n",
      "Epoch 492/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4368 - accuracy: 0.7942\n",
      "Epoch 493/500\n",
      "73/73 [==============================] - 0s 360us/step - loss: 0.4332 - accuracy: 0.7942\n",
      "Epoch 494/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.4522 - accuracy: 0.7860\n",
      "Epoch 495/500\n",
      "73/73 [==============================] - 0s 364us/step - loss: 0.4409 - accuracy: 0.7929\n",
      "Epoch 496/500\n",
      "73/73 [==============================] - 0s 356us/step - loss: 0.4263 - accuracy: 0.8025\n",
      "Epoch 497/500\n",
      "73/73 [==============================] - 0s 358us/step - loss: 0.4417 - accuracy: 0.7984\n",
      "Epoch 498/500\n",
      "73/73 [==============================] - 0s 366us/step - loss: 0.4433 - accuracy: 0.8011\n",
      "Epoch 499/500\n",
      "73/73 [==============================] - 0s 355us/step - loss: 0.4304 - accuracy: 0.8025\n",
      "Epoch 500/500\n",
      "73/73 [==============================] - 0s 544us/step - loss: 0.4272 - accuracy: 0.7984\n"
     ]
    }
   ],
   "source": [
    "result = model_improved.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.34430646896362%\n"
     ]
    }
   ],
   "source": [
    "# show best results from model_improved\n",
    "print(str(max(result.history[\"accuracy\"])*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchSize = [5,10, 20, 30]\n",
    "# epochs = [50, 100, 150, 200, 300]\n",
    "# optimizer = ['SGD','Adadelta', 'RMSprop', 'Adagrad','Adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_improved = KerasClassifier(build_fn=create_my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_grid = dict(batch_size=batchSize, epochs=epochs, optimizer=optimizer)\n",
    "\n",
    "# mygrid = GridSearchCV(estimator=model_improved, param_grid=parameter_grid, n_jobs=-1, cv=3)\n",
    "# grid_result = mygrid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(grid_result\u001b[39m.\u001b[39mcv_results_)\n\u001b[1;32m      2\u001b[0m grid_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_result' is not defined"
     ]
    }
   ],
   "source": [
    "# grid_df = pd.DataFrame(grid_result.cv_results_)\n",
    "# grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.676269 using {'batch_size': 100, 'epochs': 50, 'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 82.6%\n",
    "parameters: 500 epochs, 10 batch_size, Adam optimizer, loss='binary_crossentropy'.\n",
    "\n",
    "layers: 12 Dense, 8 Dense, 1 sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 12)                108       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "result.model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
